\section{Conclusion}
\label{sec:conclusion}

% Overall summary, open questions, next steps.
We have started to tackle the task of choosing the most important
phrases from a collection of lectures, to construct a random-access
index analogous to those in the back of books.  Going forward we will
use this capability to construct student support facilities such as
automatically answering learner questions with references to relevant
lecture clips, and recommendation tasks, such as finding the best
study materials given a student's progress through a course. There has
been little previous work on index extraction in the online education
setting, and in lecture series videos in particular. We therefore
began by evaluating the performance of term frequency-inverse document
frequency, a well-known metric for gauging the importance of a phrase
to a document. After evaluating the weaknesses of TF-IDF in this
educational context, we designed algorithms that incorporated
linguistic information, in the form of part-of-speech tags and
chunking, and external information, with the entire Wikipedia document
collection used as a knowledge source. The algorithms that incorporate
Wikipedia information boost performance of TF-IDF, especially on
longer phrases that do not have high raw frequencies in a lecture.

In the process of this work we paid three high-quality persons to
index an internationally renowned database course. We used the three
indexes to evaluate our algorithms. In an effort to allow our work to
be reproduced at other institutions, and to foster additional work in
this area we are making the three indexes and the course video
transcripts publicly available.

In the future we will explore using the rich structure provided by
the Wikipedia dataset to improve our keyword extraction
algorithms further. For example, Wikipedia grants access to the link structure
between its documents, and groups documents into collections, which are
explored for different tasks in \cite{hu2009exploiting} and \cite{milne2007computing}.

We are also interested in keyword extraction as a supervised learning
task. As previously described, one of the main challenges is the cost
of obtaining a large amount of labelled data, especially in the online
education setting where annotators often need to be highly educated
and devote a substantial amount of time to generate high quality
indexing. One possible strategy is transfer learning, where a learning
algorithm is trained on a different problem than the one on which it
will make predictions. It is possible that there are features that
differentiate important phrases in journal abstracts or newspapers
that could also differentiate important phrases in lectures. Indeed,
transfer learning for text classification has been explored previously
\cite{raina2006constructing}, \cite{do2005transfer}.

Good human-generated indexes sometimes include page references into
books for terms that do not appear in the referenced page. This
decision might be based on knowledge of synonymy, or even deeper
domain knowledge. Inclusion of synonyms has been widely studied in the
context of query expansion. But future work could reveal that indexing
terms into lectures where the term does not appear might be feasible
in automated index generators as well, based on the fact that lectures
often build on each other. Since one of the indexers did include
some synonyms such algorithms could be studied over that data.

Random access into lecture videos remains an important
challenge. Those media contain expensive-to-produce content, and
making that content as useful as possible will improve online learning
and reference opportunities.


