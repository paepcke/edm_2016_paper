\section{Conclusion}
\label{sec:conclusion}

% Overall summary, open questions, next steps.
In this paper we have started to tackle the task of choosing the most important phrases from a collection of lectures, which will be used downstream to support information retreival tasks, such as answering learner questions with relevant lecture clips, and recommendation tasks, such as finding the best study materials given their progress through the course. There has been little previous work on keyword extraction in the online education setting, so we began by evaluating the performance of term frequency-inverse document frequency, a well-known metric for gauging the importance of a phrase to a document. After evaluating the weaknesses of TF-IDF, we designed algorithms that incorporated linguistic information, in the form of part-of-speech tags and chunking, and external information, with the entire Wikipedia document collection used as a knowledge source. The algorithms that incorporate Wikipedia information boost performance of TF-IDF, especially on longer phrases that do not have high raw frequencies in a lecture. We also created a human generated set of keywords for the online introductory databases course we evaluated our algorithms on.

In the future we would like to explore using the richer structure provided by the Wikipedia dataset to improve our keyword extraction algorithms. For example, Wikipedia gives access to the link structure between documents and groups documents into collections, which are explored in \cite{hu2009exploiting} and \cite{milne2007computing} for different tasks.

We are also interested in keyword extraction as a supervised learning task. As previously described, one of the main challenges is the cost of obtaining a large amount of labelled data, especially in the online education setting where annotators often need to be highly educated and devote a substantial amount of time to generate high quality keywords. One possible strategy is transfer learning, where a learning algorithm is trained on a different problem than the one it will make predictions on. It is possible that there are features that differentiate important phrases in journal abstracts or newspapers that could also differentiate important phrases in lectures. Indeed, transfer learning for text classification has been explored previously \cite{raina2006constructing}, \cite{do2005transfer}.