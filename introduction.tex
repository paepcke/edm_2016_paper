\section{Introduction}
\label{sec:intro}

One of the biggest challenges of delivering education with massively open online courses (MOOCs) is the high student to instructor ratio, which is further compounded in courses where students don't arrive at traditional term boundaries. In the extreme, \textit{untended} courses may not have any active teaching staff. Without support, students fend for themselves when they don't understand a concept or need to review for a test. Our team is building a system to autonomously help students enrolled in unattended courses; this will enhance, not replace, human instruction and improve the support for all learners.

Extracting important phrases and concepts both directly aids learners and serves as a foundation for the rest of the system. For example, the system produces a set of keywords that index into segments of lecture videos, allowing learners to quickly find parts of lecture relevant to a topic, similarly to the way a textbook index would be used. These keywords could also be used by the system to autonomously find the lecture segment most relevant to a forum post, or other information retrieval tasks. There has been little previous work on natural language processing and content analysis in the online education setting, and development of datasets and algorithms could potentially be quite beneficial for teachers and learners.

This task of forming an index over the lectures in an online course, which we refer to as the keyword extraction task, is inherently difficult. A human performing the task must have a deep understanding of the concepts in each lecture, as well as their role in the broader context of the entire course. A 25 minute lecture video might have around 4500 individual words, from which the algorithm must form around 20 phrases to capture the content of the lecture. There is a certain amount of subjectivity inherent in the task, and there can be differing reasonable interpretations of what should be considered a keyword. When humans select important phrases from a lecture they use previous knowledge - for example, in a databases course one might use previous knowledge of functional dependencies to decide that ``Armstrong's Axiom'' should be one of the keyphrases - and we draw on this strategy to automatically decide on keyphrases.

Many keyword extraction systems are designed for use on large collections of loosely related documents, such as newspaper articles or abstracts from an academic journal. In contrast, our indexing system takes transcripts of lecture videos as input, which presents several interesting challenges. Lectures for a class are tightly linked to each other, have a well-defined sequence, and are usually delivered by only one or two instructors. Many keyword extraction algorithms leverage the fact that documents on very different topics will have mostly disjoint sets of words, which may not work as well in our setting.

We used our system to extract keywords from the content of a online introductory databases course, and then tested for agreement against a gold set of phrases produced by humans. Our first experiment took a statistical approach, selecting words that appeared frequently throughout the class, and disproportionately in certain lectures. We then incorporated lexical information, by only considering phrases that followed certain part-of-speech patterns. Finally, we were able to improve the quality of our index by incorporating external knowledge from Wikipedia pages.
